{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Real Estate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Real_estate.csv dataset into sctipt - Be sure to use local path!\n",
    "df = pd.read_csv('Real_estate.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Edits to Data & Check for missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns\n",
    "# No column is just a value thats different in every row and would not help in the training process\n",
    "\n",
    "print('Shape before edit:', df.shape)\n",
    "del df['No']\n",
    "print('Shape after edit:', df.shape)\n",
    "\n",
    "#Check for missing values\n",
    "print('\\nChecking for any missing values in columns')\n",
    "df.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define predictor & target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X and Y\n",
    "print('Dataset shape: ', df.shape)\n",
    "X = df.drop(['Y house price of unit area'],axis=1).values\n",
    "Y = df['Y house price of unit area'].values\n",
    "\n",
    "#New sets of data\n",
    "print('X (predictor variables) shape:       ', X.shape)\n",
    "print('Y (target variable)     shape:       ',Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Performance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function gets the score/accuracy - based on model selected\n",
    "def get_score(model, X_train, X_test, Y_train, Y_test):\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting model for graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(X_train, X_test, Y_train, Y_test ):\n",
    "  lin = LinearRegression()\n",
    "  lin.fit(X_train, Y_train)\n",
    "  \n",
    "  lasso = linear_model.Lasso()\n",
    "  lasso.fit(X_train, Y_train)\n",
    "  \n",
    "  ridge = linear_model.Ridge()\n",
    "  ridge.fit(X_train, Y_train)\n",
    "  \n",
    "  elNet = linear_model.ElasticNet()\n",
    "  elNet.fit(X_train, Y_train)\n",
    "\n",
    "  lin_y_train_pred = lin.predict(X_train)\n",
    "  lin_y_test_pred = lin.predict(X_test)\n",
    "\n",
    "  lasso_y_train_pred = lasso.predict(X_train)\n",
    "  lasso_y_test_pred = lasso.predict(X_test) \n",
    "\n",
    "  ridge_y_train_pred = ridge.predict(X_train)\n",
    "  ridge_y_test_pred = ridge.predict(X_test)\n",
    "\n",
    "  elNet_y_train_pred = elNet.predict(X_train)\n",
    "  elNet_y_test_pred = elNet.predict(X_test)\n",
    "\n",
    "\n",
    "  _,ax = plt.subplots(2,4, figsize =(15,10), sharex=True, sharey=True)\n",
    "  ax[0,0].set_title(\"LinReg Train\")\n",
    "  ax[0,0].scatter(Y_train, lin_y_train_pred, marker=\"o\",alpha=0.5)\n",
    "  ax[1,0].set_title('LinReg Test')\n",
    "  ax[1,0].scatter(Y_test, lin_y_test_pred,  marker=\"o\",color='g', label='LinReg Test', alpha=0.5)\n",
    "  ax[0,1].set_title(\"Lasso Train\")  \n",
    "  ax[0,1].scatter(Y_train, lasso_y_train_pred,  marker='^',label='Lasso Train', alpha=0.5)\n",
    "  ax[1,1].set_title(\"Lasso Test\")\n",
    "  ax[1,1].scatter(Y_test, lasso_y_test_pred, marker=\"^\", color='g', label='Lasso Test', alpha=0.5)\n",
    "  ax[0,2].set_title(\"Ridge Train\")\n",
    "  ax[0,2].scatter(Y_train, ridge_y_train_pred,  marker=\"s\",  label='Ridge Train', alpha=0.5)\n",
    "  ax[1,2].set_title(\"Ridge Test\")\n",
    "  ax[1,2].scatter(Y_test, ridge_y_test_pred,  marker=\"s\", color='g', label='Ridge Test', alpha=0.5)\n",
    "  ax[0,3].set_title(\"ElNet Train\")\n",
    "  ax[0,3].scatter(Y_train, elNet_y_train_pred,  marker=\"x\", label='ElNet Train', alpha=0.5)\n",
    "  ax[1,3].set_title(\"ElNet Test\")\n",
    "  ax[1,3].scatter(Y_test, elNet_y_test_pred,  marker=\"x\", color='g',label='ElNet Test',alpha=0.5)\n",
    "  \n",
    "  \n",
    "  plt.suptitle('Actual vs Predicted - New Fold')\n",
    "  plt.show()\n",
    "  lin_mse = np.mean(( lin_y_test_pred - Y_test)**2)\n",
    "  lasso_mse = np.mean(( lasso_y_test_pred - Y_test)**2)\n",
    "  ridge_mse = np.mean(( ridge_y_test_pred - Y_test)**2)\n",
    "  elNet_mse = np.mean(( elNet_y_test_pred - Y_test)**2)\n",
    "  print(f'\\n  LinearReg MSE: {lin_mse:0.3}\\t\\t  Lasso MSE: {lasso_mse:0.3}\\t\\t Ridge MSE: {ridge_mse:0.3}\\t\\tElasticNet MSE: {elNet_mse:0.3}\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(X_train,  X_test, Y_train, Y_test, model ):\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_test_pred = model.predict(X_test)\n",
    "    mse_val = np.mean(( Y_test_pred - Y_test)**2)\n",
    "    return mse_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm for all regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_scores = []\n",
    "lasso_scores = []\n",
    "ridge_scores = []\n",
    "elastic_net_scores = []\n",
    "\n",
    "lin_mse = []\n",
    "lasso_mse = []\n",
    "ridge_mse = []\n",
    "elasticNet_mse = []\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    # Scores for models\n",
    "    ml_scores.append(get_score(LinearRegression(), X_train, X_test, Y_train, Y_test))\n",
    "    lasso_scores.append(get_score(linear_model.Lasso(),  X_train, X_test, Y_train, Y_test))\n",
    "    ridge_scores.append(get_score(linear_model.Ridge(),  X_train, X_test, Y_train, Y_test))\n",
    "    elastic_net_scores.append(get_score(linear_model.ElasticNet(),  X_train, X_test, Y_train, Y_test))\n",
    "    \n",
    "    # Graphs for models\n",
    "    plot_model(X_train, X_test, Y_train, Y_test)\n",
    "    \n",
    "    # MSE for models\n",
    "    lin_mse.append(mse(X_train, X_test, Y_train, Y_test, LinearRegression()))\n",
    "    lasso_mse.append(mse(X_train, X_test, Y_train, Y_test, linear_model.Lasso()))\n",
    "    ridge_mse.append(mse(X_train, X_test, Y_train, Y_test, linear_model.Ridge()))\n",
    "    elasticNet_mse.append(mse(X_train, X_test, Y_train, Y_test, linear_model.ElasticNet()))\n",
    "\n",
    "\n",
    "print(\"\\033[31;1;4mAccuracy measurement each Kfold iteration:\\033[0m\\n\")\n",
    "print('Linear Regression:', ml_scores, '\\nLasso:            ', lasso_scores, '\\nRidge:            ', ridge_scores, '\\nElastic Net:      ', elastic_net_scores )\n",
    "print('\\n')\n",
    "print(\"\\033[31;1;4mModel Accuracy after conducting Kfold:\\033[0m\\n\\n\")\n",
    "print('Linear Regression:', np.mean(ml_scores), '\\nLasso Regression:', np.mean(lasso_scores),\\\n",
    "      '\\nRidge Regression:', np.mean(ridge_scores), '\\nElasticNet Regression', np.mean(elastic_net_scores))  \n",
    "\n",
    "print(\"\\n\\033[31;1;4mModel MSE after conducting Kfold:\\033[0m\\n\\n\")\n",
    "print('Linear Regression MSE:', np.mean(lin_mse), '\\nLasso Regression MSE:', np.mean(lasso_mse),\\\n",
    "      '\\nRidge Regression MSE :', np.mean(ridge_mse), '\\nElasticNet Regression MSE:', np.mean(elasticNet_mse))  \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"\\n\\033[31;1;4mAccuracies for models verified by the sklearn.model_selection.cross_val_score function\\033[0m\\n\\n\")\n",
    "print(\"Linear Regression:\\t  \",np.mean(cross_val_score(LinearRegression(), X, Y)))\n",
    "print(\"Lasso Regression:\\t  \", np.mean(cross_val_score(linear_model.Lasso(), X, Y)))\n",
    "print(\"Ridge Regression:\\t  \", np.mean(cross_val_score(linear_model.Ridge(), X, Y)))\n",
    "print(\"Elastic Net Regression:   \", np.mean(cross_val_score(linear_model.ElasticNet(), X, Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Paramaters for Individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "best_acc_model = []\n",
    "\n",
    "def model_param_tuning(X,Y):\n",
    "    model_algos = {\n",
    "        'Linear Regression' : {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'normalize': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'Lasso Regression': {\n",
    "            'model': linear_model.Lasso(),\n",
    "            'params': {\n",
    "                'alpha': np.logspace(-10,1,10),\n",
    "                'normalize': [True,False],\n",
    "                'selection': ['random','cyclic']\n",
    "            }\n",
    "        },\n",
    "        'Ridge Regression': {\n",
    "            'model': linear_model.Ridge(),\n",
    "            'params': {\n",
    "                'alpha': np.logspace(-10,1,10),\n",
    "                'normalize': [True,False]\n",
    "            }\n",
    "        },\n",
    "        'ElasticNet Regression': {\n",
    "            'model': linear_model.ElasticNet(),\n",
    "            'params': {\n",
    "                'alpha': np.logspace(-10,1,10),\n",
    "                'normalize': [True,False],\n",
    "                'selection': ['random','cyclic']\n",
    "     \n",
    "            }\n",
    "        }   \n",
    "    }\n",
    "\n",
    "        \n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=100)\n",
    "    \n",
    "    for algo_name, config in model_algos.items():\n",
    "        grid_search = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        grid_search.fit(X,Y)\n",
    "        scores.append({\n",
    "            'model':algo_name,\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'best_params': grid_search.best_params_\n",
    "        })\n",
    "    \n",
    "    tuned = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "    best_model = tuned.loc[tuned['best_score'].idxmax()]\n",
    "    print(\"\\n\\033[31;1;4mModel with highest accuracy\\033[0m\\n\\n\")\n",
    "    print(\"Model name:\\t\\t     \" , best_model['model'])\n",
    "    print(\"Best accuracy score:\\t     \", best_model['best_score'])\n",
    "    print(\"Best parameters:\\t     \", best_model['best_params'])\n",
    "    print('\\n')\n",
    "    print(\"\\033[31;1;4mTable with model scores after hyperparameter tuning\\033[0m\\n\\n\")\n",
    "    return tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_tuning(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
